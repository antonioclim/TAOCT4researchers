# 13UNIT: Self-Assessment Checklist

## Machine Learning for Researchers

---

## Instructions

Complete this self-assessment after finishing all laboratory exercises and before submitting homework. For each item, honestly evaluate your current competency level.

**Rating Scale**:
- ‚úÖ **Confident**: I can do this independently and explain it to others
- üî∂ **Developing**: I can do this with reference materials
- ‚ùå **Need Review**: I struggle with this concept

---

## Learning Objective 1: Paradigm Distinction

*Can you distinguish supervised, unsupervised and reinforcement learning paradigms?*

| Competency | Self-Rating | Notes |
|------------|-------------|-------|
| Define supervised learning and identify when it applies | ‚¨ú | |
| Distinguish classification from regression problems | ‚¨ú | |
| Define unsupervised learning and its applications | ‚¨ú | |
| Explain when clustering vs dimensionality reduction applies | ‚¨ú | |
| Describe reinforcement learning conceptually | ‚¨ú | |
| Given a research problem, select the appropriate paradigm | ‚¨ú | |

**Reflection**: If you marked any items ‚ùå, review lecture notes Section 2.

---

## Learning Objective 2: Pipeline Implementation

*Can you implement ML pipelines using scikit-learn?*

| Competency | Self-Rating | Notes |
|------------|-------------|-------|
| Use the Estimator API (fit, predict, transform) | ‚¨ú | |
| Create Pipeline objects for sequential transformations | ‚¨ú | |
| Use ColumnTransformer for heterogeneous features | ‚¨ú | |
| Apply StandardScaler, MinMaxScaler for numerical features | ‚¨ú | |
| Apply OneHotEncoder for categorical features | ‚¨ú | |
| Train classifiers: LogisticRegression, RandomForest, SVC | ‚¨ú | |
| Train regressors: LinearRegression, Ridge, Lasso | ‚¨ú | |
| Generate predictions and probability estimates | ‚¨ú | |

**Reflection**: If you marked any items ‚ùå, redo Lab 01 Sections 1‚Äì3.

---

## Learning Objective 3: Validation Methodology

*Can you apply proper validation protocols?*

| Competency | Self-Rating | Notes |
|------------|-------------|-------|
| Perform train/test split with appropriate test size | ‚¨ú | |
| Apply stratification for classification problems | ‚¨ú | |
| Implement k-fold cross-validation | ‚¨ú | |
| Use StratifiedKFold for imbalanced data | ‚¨ú | |
| Interpret mean and std of CV scores | ‚¨ú | |
| Explain why nested CV provides unbiased estimates | ‚¨ú | |
| Implement nested cross-validation | ‚¨ú | |
| Identify data leakage scenarios | ‚¨ú | |
| Prevent leakage using Pipelines | ‚¨ú | |

**Reflection**: If you marked any items ‚ùå, review Lab 01 Section 4 and lecture notes Section 4.

---

## Learning Objective 4: Metric Interpretation

*Can you select and interpret appropriate evaluation metrics?*

| Competency | Self-Rating | Notes |
|------------|-------------|-------|
| Construct and interpret confusion matrices | ‚¨ú | |
| Calculate accuracy from confusion matrix | ‚¨ú | |
| Calculate precision and explain its meaning | ‚¨ú | |
| Calculate recall and explain its meaning | ‚¨ú | |
| Calculate F1-score and when to use it | ‚¨ú | |
| Interpret ROC curves and AUC | ‚¨ú | |
| Calculate MSE, RMSE for regression | ‚¨ú | |
| Interpret R¬≤ and its limitations | ‚¨ú | |
| Select metrics based on problem costs | ‚¨ú | |
| Explain why accuracy is misleading for imbalanced data | ‚¨ú | |

**Reflection**: If you marked any items ‚ùå, review lecture notes Section 5 and complete easy exercise 3.

---

## Learning Objective 5: Pitfall Mitigation

*Can you identify and address common ML pitfalls?*

| Competency | Self-Rating | Notes |
|------------|-------------|-------|
| Recognise overfitting from train/test performance gap | ‚¨ú | |
| Interpret learning curves for overfitting diagnosis | ‚¨ú | |
| Apply regularisation to reduce overfitting | ‚¨ú | |
| Recognise underfitting symptoms | ‚¨ú | |
| Explain bias-variance trade-off conceptually | ‚¨ú | |
| Identify data leakage in code | ‚¨ú | |
| Detect class imbalance from data exploration | ‚¨ú | |
| Apply class weights to address imbalance | ‚¨ú | |
| Use resampling techniques (SMOTE, undersampling) | ‚¨ú | |
| Adjust classification threshold for imbalanced data | ‚¨ú | |

**Reflection**: If you marked any items ‚ùå, redo Lab 01 Section 5 and hard exercise 2.

---

## Learning Objective 6: Unsupervised Implementation

*Can you implement clustering and dimensionality reduction?*

| Competency | Self-Rating | Notes |
|------------|-------------|-------|
| Implement k-means clustering | ‚¨ú | |
| Use elbow method to select k | ‚¨ú | |
| Implement hierarchical clustering | ‚¨ú | |
| Interpret dendrograms | ‚¨ú | |
| Implement DBSCAN for density-based clustering | ‚¨ú | |
| Calculate and interpret silhouette scores | ‚¨ú | |
| Implement PCA for dimensionality reduction | ‚¨ú | |
| Interpret explained variance ratios | ‚¨ú | |
| Create scree plots | ‚¨ú | |
| Implement t-SNE for visualisation | ‚¨ú | |
| Understand t-SNE limitations | ‚¨ú | |

**Reflection**: If you marked any items ‚ùå, redo Lab 02 and medium exercise 3.

---

## Code Quality Self-Check

| Requirement | Verified | Notes |
|-------------|----------|-------|
| All functions have type hints | ‚¨ú | |
| All functions have Google-style docstrings | ‚¨ú | |
| `ruff check` passes with no errors | ‚¨ú | |
| `mypy --strict` passes with no errors | ‚¨ú | |
| Random states set for reproducibility | ‚¨ú | |
| No hardcoded file paths | ‚¨ú | |
| No magic numbers (constants named) | ‚¨ú | |
| Logging used instead of print statements | ‚¨ú | |

---

## Conceptual Understanding Verification

Answer these questions without reference materials:

1. **What is the difference between precision and recall?**

   Your answer: _________________________________________________

2. **Why might a model with 99% accuracy still be useless?**

   Your answer: _________________________________________________

3. **What is data leakage and how do you prevent it?**

   Your answer: _________________________________________________

4. **When would you use nested cross-validation instead of standard CV?**

   Your answer: _________________________________________________

5. **How does PCA differ from t-SNE for dimensionality reduction?**

   Your answer: _________________________________________________

---

## Summary Assessment

Count your ratings:

| Rating | Count |
|--------|-------|
| ‚úÖ Confident | ____ / 57 |
| üî∂ Developing | ____ / 57 |
| ‚ùå Need Review | ____ / 57 |

**Readiness Assessment**:
- ‚â•50 ‚úÖ: Ready to submit
- 40‚Äì49 ‚úÖ: Minor review recommended
- 30‚Äì39 ‚úÖ: Significant review needed
- <30 ‚úÖ: Complete additional practice before submission

---

## Action Plan

Based on your self-assessment, identify areas needing improvement:

1. **Priority 1**: _______________________________________________

2. **Priority 2**: _______________________________________________

3. **Priority 3**: _______________________________________________

**Planned Actions**:

- [ ] Review lecture notes sections: _______________
- [ ] Redo laboratory sections: _______________
- [ ] Complete additional exercises: _______________
- [ ] Seek help on: _______________

---

## Declaration

By submitting this self-assessment, I confirm that:

- [ ] I have honestly evaluated my competencies
- [ ] I have completed all required laboratory exercises
- [ ] My code meets the specified quality standards
- [ ] I understand the material well enough to explain it to a peer

**Signature**: _________________________ **Date**: _____________

---
