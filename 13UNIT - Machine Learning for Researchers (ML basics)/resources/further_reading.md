# 13UNIT: Further Reading

## Machine Learning for Researchers

---

## Foundational Textbooks

### 1. The Elements of Statistical Learning
**Authors**: Hastie, T., Tibshirani, R., & Friedman, J.  
**Publisher**: Springer (2009, 2nd edition)  
**URL**: https://hastie.su.domains/ElemStatLearn/

The definitive graduate-level treatment of statistical learning methods. Mathematically rigorous with excellent coverage of bias-variance trade-off, regularisation and ensemble methods. Available as a free PDF from the authors.

### 2. Pattern Recognition and Machine Learning
**Author**: Bishop, C. M.  
**Publisher**: Springer (2006)

Comprehensive probabilistic perspective on machine learning. Excellent treatment of Bayesian methods, graphical models and kernel methods. More mathematically demanding than applied texts but provides deep theoretical foundations.

### 3. An Introduction to Statistical Learning
**Authors**: James, G., Witten, D., Hastie, T., & Tibshirani, R.  
**Publisher**: Springer (2021, 2nd edition)  
**URL**: https://www.statlearning.com/

Accessible introduction to statistical learning with applications in R (and now Python). Less mathematical than *Elements* but covers key concepts with clarity. Excellent for researchers new to the field.

---

## Practical Guides

### 4. Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow
**Author**: Géron, A.  
**Publisher**: O'Reilly (2022, 3rd edition)

The most practical guide to implementing machine learning in Python. Covers scikit-learn extensively with clear examples. Highly recommended for hands-on learning.

### 5. Introduction to Machine Learning with Python
**Authors**: Müller, A. C., & Guido, S.  
**Publisher**: O'Reilly (2016)

Focused exclusively on scikit-learn with excellent coverage of the API and common workflows. Written by a scikit-learn core developer.

### 6. Python Machine Learning
**Authors**: Raschka, S., & Mirjalili, V.  
**Publisher**: Packt (2019, 3rd edition)

Comprehensive practical guide covering scikit-learn and deep learning. Good balance of theory and implementation.

---

## Specialised Topics

### 7. Feature Engineering for Machine Learning
**Authors**: Zheng, A., & Casari, A.  
**Publisher**: O'Reilly (2018)

Dedicated treatment of feature engineering—often the most important factor in ML success. Covers numerical, categorical, text and image features.

### 8. Imbalanced Learning: Foundations, Algorithms, and Applications
**Editors**: He, H., & Ma, Y.  
**Publisher**: Wiley (2013)

Comprehensive treatment of class imbalance problems. Covers resampling, cost-sensitive learning and ensemble approaches.

### 9. Interpretable Machine Learning
**Author**: Molnar, C.  
**Publisher**: Self-published (2022, 2nd edition)  
**URL**: https://christophm.github.io/interpretable-ml-book/

Free online book covering model interpretability techniques: LIME, SHAP, partial dependence plots and more. Essential for research applications requiring explainability.

---

## Research Papers

### 10. Random Forests
**Authors**: Breiman, L.  
**Journal**: Machine Learning, 45(1), 5-32 (2001)

The foundational paper introducing random forests. Still highly readable and provides intuition for why ensembles work.

### 11. A Few Useful Things to Know About Machine Learning
**Author**: Domingos, P.  
**Journal**: Communications of the ACM, 55(10), 78-87 (2012)  
**URL**: https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf

Excellent overview of practical ML wisdom. Covers feature engineering, overfitting, curse of dimensionality and model selection.

### 12. Scikit-learn: Machine Learning in Python
**Authors**: Pedregosa, F., et al.  
**Journal**: Journal of Machine Learning Research, 12, 2825-2830 (2011)

The original scikit-learn paper. Brief but documents the design philosophy behind the library.

### 13. SMOTE: Synthetic Minority Over-sampling Technique
**Authors**: Chawla, N. V., et al.  
**Journal**: Journal of Artificial Intelligence Research, 16, 321-357 (2002)

The foundational paper for the most widely used oversampling technique for imbalanced data.

---

## Online Resources

### 14. scikit-learn User Guide
**URL**: https://scikit-learn.org/stable/user_guide.html

The official documentation. Comprehensive coverage of all algorithms with examples. The best first resource for any scikit-learn question.

### 15. scikit-learn Tutorials
**URL**: https://scikit-learn.org/stable/tutorial/index.html

Step-by-step tutorials covering basic usage, text data and model selection.

### 16. Kaggle Learn: Machine Learning
**URL**: https://www.kaggle.com/learn/intro-to-machine-learning

Interactive tutorials with hands-on exercises. Good for reinforcing concepts through practice.

### 17. Google Machine Learning Crash Course
**URL**: https://developers.google.com/machine-learning/crash-course

Free course covering ML fundamentals with TensorFlow examples. Good supplementary material for conceptual understanding.

### 18. StatQuest with Josh Starmer (YouTube)
**URL**: https://www.youtube.com/c/joshstarmer

Excellent visual explanations of statistical and ML concepts. Particularly good for intuitive understanding of algorithms.

---

## Domain-Specific Applications

### 19. Machine Learning for Biomedical and Health Informatics
**Authors**: Goldstein, B. A., et al.  
**Journal**: Annual Review of Biomedical Data Science, 1, 347-372 (2018)

Overview of ML applications in medicine with discussion of domain-specific challenges.

### 20. Machine Learning in Economics and Finance
**Authors**: Athey, S., & Imbens, G. W.  
**Journal**: Science, 355(6324), 486-491 (2017)

How ML intersects with econometric methodology. Addresses causal inference considerations.

### 21. Deep Learning for the Life Sciences
**Authors**: Bharath Ramsundar, et al.  
**Publisher**: O'Reilly (2019)

Applications of ML (including deep learning) to drug discovery, genomics and microscopy.

---

## Validation and Reproducibility

### 22. Cross-Validation Pitfalls When Selecting and Assessing Regression and Classification Models
**Authors**: Krstajic, D., et al.  
**Journal**: Journal of Cheminformatics, 6(1), 10 (2014)

Detailed treatment of cross-validation methodology and common mistakes.

### 23. Model Evaluation, Model Selection, and Algorithm Selection in Machine Learning
**Author**: Raschka, S.  
**Preprint**: arXiv:1811.12808 (2018)  
**URL**: https://arxiv.org/abs/1811.12808

Comprehensive tutorial on evaluation methodology including nested cross-validation.

---

## Reading Progression Recommendations

**Beginner Path**:
1. James et al. (2021) — *An Introduction to Statistical Learning*
2. Géron (2022) — *Hands-On Machine Learning*
3. scikit-learn tutorials

**Intermediate Path**:
1. Müller & Guido (2016) — *Introduction to ML with Python*
2. Domingos (2012) — *A Few Useful Things*
3. Molnar (2022) — *Interpretable ML*

**Advanced Path**:
1. Hastie et al. (2009) — *Elements of Statistical Learning*
2. Bishop (2006) — *Pattern Recognition and ML*
3. Original algorithm papers

---
