<!doctype html><html><head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1.0'>
<title>11UNIT Slides</title>
<link rel='stylesheet' href='https://unpkg.com/reveal.js/dist/reveal.css'>
<link rel='stylesheet' href='https://unpkg.com/reveal.js/dist/theme/white.css'>
</head><body><div class='reveal'><div class='slides'>
<section><h2>11UNIT — Slide 1</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 2</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 3</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 4</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 5</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 6</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 7</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 8</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 9</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 10</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 11</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 12</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 13</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 14</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 15</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 16</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 17</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 18</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 19</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 20</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 21</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 22</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 23</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 24</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 25</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 26</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 27</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 28</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 29</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 30</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 31</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 32</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 33</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 34</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 35</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 36</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 37</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 38</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 39</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
<section><h2>11UNIT — Slide 40</h2><p>Slide content focuses on a single conceptual claim is treated here as a research-oriented craft
rather than a collection of library calls. The central question is how an analyst moves from raw
character sequences to defensible claims, given that token boundaries, normalisation choices and
annotation schemes impose inductive bias. We therefore separate specification from implementation:
we first state what a pipeline must preserve or discard, then encode those constraints as pure
functions with explicit preconditions. Attention is paid to failure modes, including ambiguous
segmentation, encoding artefacts and domain drift, since these frequently dominate error budgets in
empirical studies. In practice, the unit couples formal definitions with executable checks so that
each step has a measurable contract: input alphabet, transformation invariants and complexity
expectations.</p></section>
</div></div>
<script src='https://unpkg.com/reveal.js/dist/reveal.js'></script>
<script>Reveal.initialize({hash:true});</script>
</body></html>