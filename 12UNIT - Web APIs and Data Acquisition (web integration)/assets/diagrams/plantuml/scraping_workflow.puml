@startuml scraping_workflow
!theme plain
skinparam backgroundColor #FEFEFE

title Ethical Web Scraping Workflow

start

:Identify target website;

:Check robots.txt;
if (Path allowed?) then (yes)
  :Check Terms of Service;
  if (Scraping permitted?) then (yes)
    :Configure scraper;
    note right
      • Set User-Agent
      • Configure delay
      • Set up caching
    end note
    
    :Fetch page;
    
    if (Cached?) then (yes)
      :Return cached response;
    else (no)
      :Wait for rate limit;
      :Make HTTP request;
      :Cache response;
    endif
    
    :Parse HTML with BeautifulSoup;
    
    :Extract data;
    note right
      • CSS selectors
      • Navigate DOM tree
      • Handle missing elements
    end note
    
    if (More pages?) then (yes)
      :Find next page link;
      -> :Fetch page;
    else (no)
      :Return extracted data;
    endif
    
  else (no)
    #pink:Cannot scrape;
    :Consider API alternatives;
    stop
  endif
else (no)
  #pink:Path disallowed;
  :Respect robots.txt;
  stop
endif

stop

@enduml
